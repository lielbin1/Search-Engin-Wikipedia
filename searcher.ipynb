{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "searcher.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Setting Variables."
      ],
      "metadata": {
        "id": "TgYwOyHGF3xT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd \n",
        "nf = pd.read_pickle('/content/nf.pkl')\n",
        "print(x[1857])\n",
        "\n",
        "index_body = pd.read_pickle('/content/index.pkl')\n",
        "print(ib.df)\n",
        "zibi = read_posting_list(t, \"right\")\n",
        "print(zibi)\n",
        "\n",
        "index_anchor = pd.read_pickle('/content/index_anchor_text.pkl')\n",
        "print(read_posting_list(index_anchor,\"north\"))\n",
        "\n",
        "ib_title = pd.read_pickle('/content/index_title.pkl')\n",
        "print(ib_title.df)\n",
        "print(read_posting_list(ib_title,'upon'))\n",
        "\n",
        "id_of_title = pd.read_pickle('/content/id_title.pkl')\n",
        "print(id_of_title[1857])\n",
        "\n",
        "page_view = pd.read_pickle('/content/pageviews-202108-user.pkl')\n"
      ],
      "metadata": {
        "id": "xuFIMQ5fEZBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "cosin similarity"
      ],
      "metadata": {
        "id": "y3AcVVAPF6mq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R1_mG0QsDrIN"
      },
      "outputs": [],
      "source": [
        "def sim(q,d, index):\n",
        "  nf = pd.read_pickle('/content/nf.pkl')\n",
        "  wij = pd.read_pickle('/content/tfidf.pkl')\n",
        "  # print(wij)\n",
        "  simd_q = 0\n",
        "  cosinesim = {}\n",
        "  word_weight_in_query = {}\n",
        "  # inverted_body_= pd.read_pickle('/content/index.pkl')\n",
        "  list_of_tokens =  [token.group() for token in RE_WORD.finditer(q.lower()) if token.group() not in all_stopwords]\n",
        "  counter = Counter(list_of_tokens)\n",
        "  # print(counter)\n",
        "  wiq_wid = 0\n",
        "  wiq_pow_qr = 0\n",
        "  for k, v in counter.items():\n",
        "    post = read_posting_list(index, k)\n",
        "    # print(post)\n",
        "    if post is not None:\n",
        "      if d in post.keys():\n",
        "        tf = post[d] / nf[d][1]\n",
        "      else:\n",
        "        tf = 0\n",
        "      if k in index.df.keys():\n",
        "        idf = math.log(len(nf) / index.df[k])\n",
        "      else:\n",
        "        idf = 0\n",
        "    else:\n",
        "      tf = 0\n",
        "      idf = 0\n",
        "    wiq_wid += (tf * idf)\n",
        "    wiq_pow_qr += v ** 2\n",
        "  # print(wiq_wid)\n",
        "  wiq_pow_qr = wiq_pow_qr ** 0.5\n",
        "  # print(wij[d]** 0.5)\n",
        "  simd_q = wiq_wid / (wiq_pow_qr * (wij[d] ** 0.5))\n",
        "  return (d, simd_q)\n",
        "\n",
        "ib = pd.read_pickle('/content/index.pkl')\n",
        "# print(inverted_body.df[])\n",
        "print(sim(\"right right approval lo2018 fargo north dakota passed local ballot initiative adopting approval voting for the city's local  elections and was used elect officials', 'june', '2020', 'becoming', 'the', 'first', 'united', 'states'city and jurisdiction adopt approval voting november 2020 louis missouri passed proposition authorize variant approval voting unified primary formunicip 1857 ,inverted_body'\", 1857, ib))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def top_n_cosimilarity(q,n,index):\n",
        "  nf_l = pd.read_pickle('/content/nf.pkl')\n",
        "  id_title = pd.read_pickle('/content/id_title.pkl')\n",
        "  result = []\n",
        "  list_score = []\n",
        "  for d in nf_l.keys():\n",
        "    list_score.append(sim(q, d, index))\n",
        "  list_score.sort(key=lambda y: y[1], reverse=True)\n",
        "  for i in range(n):\n",
        "    result.append((list_score[i][0], id_title[list_score[i][0]]))\n",
        "  return result\n",
        "\n",
        "print(top_n_cosimilarity(\"approval voting\", 5, ib))"
      ],
      "metadata": {
        "id": "WVl3Tx3ID5-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def serch_title(q,index):\n",
        "  # print(q)\n",
        "  list_of_pair_title = []\n",
        "  title = pd.read_pickle('/content/id_title.pkl')\n",
        "  # index_title = pd.read_pickle('/content/index_title.pkl')\n",
        "  # print(index_title.df)\n",
        "  temp= defaultdict(int)\n",
        "  list_of_tokens =  [token.group() for token in RE_WORD.finditer(q.lower())]\n",
        "  # print(list_of_tokens)\n",
        "  for tok in list_of_tokens:\n",
        "    # print(tok)\n",
        "    temp = dsum(read_posting_list(index,tok),temp)\n",
        "    print(temp)\n",
        "  temp = sorted(temp.items(), key=lambda kv: kv[1], reverse=True)\n",
        "  # print(temp)\n",
        "  if temp is not None:\n",
        "    for tup in temp:\n",
        "      # print(tup)\n",
        "      list_of_pair_title.append((tup[0],title[tup[0]]))\n",
        "  return list_of_pair_title\n",
        "\n",
        "def dsum(*dicts):\n",
        "    ret = defaultdict(int)\n",
        "    for d in dicts:\n",
        "        for k, v in d.items():\n",
        "            ret[k] += v\n",
        "    return dict(ret)\n",
        "\n",
        "\n",
        "print(serch_title('national basketball', ib_title))"
      ],
      "metadata": {
        "id": "2h5macO5EU_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def serch_anchor(q,index):\n",
        "  list_of_pair_anchor = []\n",
        "  title = pd.read_pickle('/content/id_title.pkl')\n",
        "  # print(index.df)\n",
        "  temp= defaultdict(int)\n",
        "  list_of_tokens =  [token.group() for token in RE_WORD.finditer(q.lower())]\n",
        "  # print(list_of_tokens)\n",
        "  for tok in list_of_tokens:\n",
        "    post = read_posting_list(index,tok)\n",
        "    if post is not None:\n",
        "      temp = dsum(read_posting_list(index,tok),temp)\n",
        "  temp = sorted(temp.items(), key=lambda kv: kv[1], reverse=True)\n",
        "  if temp is not None:\n",
        "    for tup in temp:\n",
        "      list_of_pair_anchor.append((tup[0],title[tup[0]]))\n",
        "  return list_of_pair_anchor\n",
        "\n",
        "\n",
        "print(serch_anchor(\"north\",index_anchor ))"
      ],
      "metadata": {
        "id": "5n3iSYkaFR4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "page rank"
      ],
      "metadata": {
        "id": "-uK7yfkKFWr-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def page_rank(list_of_id):\n",
        "  pr = spark.read.csv(\"/content/pr\")\n",
        "  result = []\n",
        "  for id in list_of_id:\n",
        "    result.append(pr.filter(pr._c0 == id).collect()[0]._c1)\n",
        "  return result\n",
        "\n",
        "print(page_rank([13404, 9232, 32927]))"
      ],
      "metadata": {
        "id": "5dMlGLS1FV6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "e9de3f7YFZtj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}